{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Required libraries to import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import pickle\n",
    "import per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and storing GMM models for each phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfcc_dir = 'models/withenergy/mfcc_13_2/'\n",
    "TEST_DF = 'features/t_13_mfcc.hdf'\n",
    "ENERGY_FLAG = False # To include energy co-efficient or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the hdf file got by generation from the import_timit.py file \n",
    "timit_train_df = pd.read_hdf(TRAIN_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6.827545062911363, -31.824121059207688, -6.55...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[6.70766922870581, -25.256157140416256, -4.668...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7.159189212079523, -23.604278562432256, -13.0...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[8.2792130032043, -22.048277126965345, -24.025...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[8.51029438049915, -23.544322286337103, -29.46...</td>\n",
       "      <td>sil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features labels\n",
       "0  [6.827545062911363, -31.824121059207688, -6.55...    sil\n",
       "1  [6.70766922870581, -25.256157140416256, -4.668...    sil\n",
       "2  [7.159189212079523, -23.604278562432256, -13.0...    sil\n",
       "3  [8.2792130032043, -22.048277126965345, -24.025...    sil\n",
       "4  [8.51029438049915, -23.544322286337103, -29.46...    sil"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first 5 rows of the table\n",
    "timit_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting features and labels from the train set\n",
    "train_features = np.array(timit_train_df[\"features\"].tolist())\n",
    "train_labels = np.array(timit_train_df[\"labels\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1236543, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if not ENERGY_FLAG:\\n\\n    rem = [0,12,24]\\n\\n    for i in rem:\\n        train_features = np.delete(train_features,i,1)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array indices to delete\n",
    "# TODO : create a flag variable\n",
    "\n",
    "'''if not ENERGY_FLAG:\n",
    "\n",
    "    rem = [0,12,24]\n",
    "\n",
    "    for i in rem:\n",
    "        train_features = np.delete(train_features,i,1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1236543, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'aa',\n",
       " 'ae',\n",
       " 'ah',\n",
       " 'aw',\n",
       " 'ay',\n",
       " 'b',\n",
       " 'ch',\n",
       " 'd',\n",
       " 'dh',\n",
       " 'dx',\n",
       " 'eh',\n",
       " 'er',\n",
       " 'ey',\n",
       " 'f',\n",
       " 'g',\n",
       " 'hh',\n",
       " 'ih',\n",
       " 'iy',\n",
       " 'jh',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'ng',\n",
       " 'ow',\n",
       " 'oy',\n",
       " 'p',\n",
       " 'r',\n",
       " 's',\n",
       " 'sh',\n",
       " 'sil',\n",
       " 't',\n",
       " 'th',\n",
       " 'uh',\n",
       " 'uw',\n",
       " 'v',\n",
       " 'w',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows a list of the unique labels in a sorted manner\n",
    "sorted(list(set(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training a gmm for each phoneme of the label_list and storing it in a directory in a pickled format\n",
    "for index,i in enumerate(sorted(list(set(train_labels)))):\n",
    " gmm = GaussianMixture(n_components=64,covariance_type='diag')\n",
    " print('Phoneme ',index+1,' : ',i)\n",
    " gmm.fit(train_features[train_labels == i])\n",
    " if(i==''):\n",
    "     pickle.dump(gmm,open(mfcc_dir+'blank.pkl','wb'))\n",
    " else:\n",
    "     pickle.dump(gmm,open(mfcc_dir+i+'.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replacing the blank phoneme label with the word 'blank'\n",
    "sortlabels = sorted(list(set(train_labels)))\n",
    "sortlabels[0] = 'blank'\n",
    "sortlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating array to store all models\n",
    "gmm_models=[]\n",
    "\n",
    "# Loading and storing all 39 models into array\n",
    "for i in sortlabels:\n",
    "    with open(mfcc_dir+i+'.pkl','rb') as pkl_file:\n",
    "        gmm_models.append(pickle.load(pkl_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(gmm_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Accuracy\n",
    "train_scores=[]\n",
    "# MAP calculation for each of the 39 models. Finally an array of arrays is got\n",
    "for i in range(len(gmm_models)):\n",
    "    print(\"MAP calculation for GMM model of phoneme \",i+1,': ',sortlabels[i])\n",
    "    train_scores.append(gmm_models[i].score_samples(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting labels using argmax indices\n",
    "pred_labels=np.array(sorted(list(set(train_labels))))[np.argmax((np.transpose(train_scores)),axis=1)]\n",
    "# Accuracy\n",
    "train_acc = (np.count_nonzero(pred_labels==train_labels)/len(train_labels))*100\n",
    "print(\"Training Accuracy: \",train_acc,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
